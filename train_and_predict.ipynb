{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 51 conversations from files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\parma\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 38\n",
      "Testing samples: 13\n",
      "Fraud in train: 19 | Not fraud in train: 19\n",
      "Fraud in test: 7 | Not fraud in test: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 10:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.712200</td>\n",
       "      <td>0.723762</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.715800</td>\n",
       "      <td>0.689297</td>\n",
       "      <td>0.461538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.673500</td>\n",
       "      <td>0.635067</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.594800</td>\n",
       "      <td>0.556011</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.488700</td>\n",
       "      <td>0.384005</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.337122</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.283251</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>0.231979</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.154100</td>\n",
       "      <td>0.200229</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.087622</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to './results/checkpoint-best'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Step 1: Read data from fraud and not_fraud folders\n",
    "def load_conversations_from_files(fraud_dir=\"fraud\", not_fraud_dir=\"not_fraud\"):\n",
    "    conversations = []\n",
    "    labels = []\n",
    "    \n",
    "    for folder, label in [(fraud_dir, 1), (not_fraud_dir, 0)]:\n",
    "        if os.path.exists(folder):\n",
    "            for filename in os.listdir(folder):\n",
    "                if filename.endswith(\".txt\"):\n",
    "                    with open(os.path.join(folder, filename), 'r', encoding='utf-8') as f:\n",
    "                        conversation = f.read().strip()\n",
    "                        conversations.append(conversation)\n",
    "                        labels.append(label)\n",
    "        else:\n",
    "            print(f\"Warning: Directory '{folder}' not found.\")\n",
    "    \n",
    "    if not conversations:\n",
    "        raise ValueError(\"No conversation files found.\")\n",
    "    \n",
    "    return pd.DataFrame({'conversation': conversations, 'label': labels})\n",
    "\n",
    "# Load data\n",
    "try:\n",
    "    df = load_conversations_from_files()\n",
    "    print(f\"Loaded {len(df)} conversations from files.\")\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    df = pd.DataFrame({\n",
    "        'conversation': [\n",
    "            \"Urgent! Your bank account is compromised. Share your PIN now.\",\n",
    "            \"Hi, this is your doctorâ€™s office confirming tomorrowâ€™s appointment.\"\n",
    "        ],\n",
    "        'label': [1, 0]\n",
    "    })\n",
    "    print(\"Using fallback sample data (2 samples).\")\n",
    "\n",
    "# Step 2: Prepare data for BERT\n",
    "class ConversationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):  # Increased max_len\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Load BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['conversation'], df['label'], test_size=0.25, stratify=df['label'], random_state=42\n",
    ")\n",
    "print(\"Training samples:\", len(X_train))\n",
    "print(\"Testing samples:\", len(X_test))\n",
    "print(\"Fraud in train:\", y_train.sum(), \"| Not fraud in train:\", len(y_train) - y_train.sum())\n",
    "print(\"Fraud in test:\", y_test.sum(), \"| Not fraud in test:\", len(y_test) - y_test.sum())\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ConversationDataset(X_train.tolist(), y_train.tolist(), tokenizer, max_len=256)\n",
    "test_dataset = ConversationDataset(X_test.tolist(), y_test.tolist(), tokenizer, max_len=256)\n",
    "\n",
    "# Step 3: Train the model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=10,  # Increased from 5\n",
    "    per_device_train_batch_size=4,  # Reduced for better gradient updates\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=200,  # Adjusted for longer training\n",
    "    weight_decay=0.05,  # Increased to prevent overfitting\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    learning_rate=2e-5,  # Explicitly set for better fine-tuning\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=lambda p: {'accuracy': (p.predictions.argmax(-1) == p.label_ids).mean()}\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model('./results/checkpoint-best')\n",
    "print(\"Model saved to './results/checkpoint-best'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Conversation Script from 'test_conversation.txt':\n",
      "'Hi, this is Amit from India Post.\n",
      "He said your package is arriving today.\n",
      "He told me itâ€™s been shipped from Bangalore.\n",
      "He mentioned that itâ€™s a small parcel for you.\n",
      "I asked if youâ€™d be home, and he said to confirm.\n",
      "He said itâ€™ll arrive by 4 PMâ€”track it online!\n",
      "He added that the tracking is #987654321.\n",
      "He asked if the address is still correct.\n",
      "I told him Iâ€™d check with youâ€”he was fine with that.\n",
      "He said to call 555-5678 if youâ€™re out.\n",
      "Meanwhile, this is Priya from your bank.\n",
      "She said thereâ€™s a problem with your account too.\n",
      "She told me someone tried a â‚¹20,000 withdrawal.\n",
      "She mentioned that itâ€™s flagged as suspicious.\n",
      "I asked what to do, and she replied quickly.\n",
      "She said to send your PIN and card number now.\n",
      "She warned that your savings are at risk!\n",
      "She said to reply within 10 minutesâ€”urgent!\n",
      "She assured me itâ€™s safe once you do.\n",
      "Act fast, she urgedâ€”donâ€™t lose your money!'\n",
      "\n",
      "Prediction: Fraud (Confidence: 93.90%)\n",
      "Fraud Probability: 93.90% | Not Fraud Probability: 6.10%\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Predict new conversation script with confidence\n",
    "def predict_conversation_script(file_path, model, tokenizer, max_len=256):\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Error: File '{file_path}' not found.\")\n",
    "        return None\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        conversation_script = f.read().strip()\n",
    "    \n",
    "    encoding = tokenizer(\n",
    "        conversation_script,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        outputs = model(encoding['input_ids'], attention_mask=encoding['attention_mask'])\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1).tolist()[0]\n",
    "        prediction = logits.argmax().item()\n",
    "        confidence = probs[prediction] * 100\n",
    "        fraud_prob = probs[1] * 100  # Fraud probability\n",
    "        not_fraud_prob = probs[0] * 100  # Not Fraud probability\n",
    "    return {\n",
    "        'label': \"Fraud\" if prediction == 1 else \"Not Fraud\",\n",
    "        'confidence': confidence,\n",
    "        'fraud_prob': fraud_prob,\n",
    "        'not_fraud_prob': not_fraud_prob,\n",
    "        'script': conversation_script\n",
    "    }\n",
    "\n",
    "# Test with a conversation from a file\n",
    "test_file = \"test_conversation.txt\"\n",
    "result = predict_conversation_script(test_file, model, tokenizer)\n",
    "if result:\n",
    "    print(f\"\\nTest Conversation Script from '{test_file}':\\n'{result['script']}'\\n\")\n",
    "    print(f\"Prediction: {result['label']} (Confidence: {result['confidence']:.2f}%)\")\n",
    "    print(f\"Fraud Probability: {result['fraud_prob']:.2f}% | Not Fraud Probability: {result['not_fraud_prob']:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
